<div class="container">

<table style="width: 100%;"><tr>
<td>OTClass</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Train the ensemble of optimal trees for classification.
</h2>

<h3>Description</h3>

<p>This function selects optimal trees for classification from a total of <code>t.initial</code> trees grown by random forest. Number of trees in the initial set, <code>t.initial</code>, is specified by the user. If not specified then the default <code>t.initial = 1000</code> is used.
</p>


<h3>Usage</h3>

<pre><code class="language-R">OTClass(XTraining, YTraining, method=c("oob+independent","oob","sub-sampling"),
p = 0.1,t.initial = NULL,nf = NULL, ns = NULL, info = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>XTraining</code></td>
<td>

<p>An <code>n x d</code> dimensional training data matrix/frame consiting of traing observation where <code>n</code> is the number of observations and <code>d</code> is the number of features.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>YTraining</code></td>
<td>

<p>A vector of length <code>n</code> consisting of class labels for the training data. Should be binary (0,1).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>Method used in the selection of optimal trees. <code>method="oob+independent"</code> used out-of-bag observation from the bootstrap sample taken for growing the individual tree for indidual tree assessment while an independent training data for their collective assessement. <code>method="oob"</code> use the out-of-bag observations both for individual and collective assessment. <code>method="sub-sampling"</code> uses a sub-sample of the training data for individual tree assessment as well as its contribution towards the ensemble.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>

<p>Percent of the best <code>t.initial</code> trees to be selected on the basis of performance on out-of-bag observations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>t.initial</code></td>
<td>

<p>Size of the initial set of classification trees.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nf</code></td>
<td>

<p>Number of features to be sampled for spliting the nodes of the trees. If equal to <code>NULL</code> then the default <code>sqrt(number of features)</code> is executed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ns</code></td>
<td>

<p>Node size: Minimal number of samples in the nodes. If equal to <code>NULL</code> then the default <code>1</code> is executed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>info</code></td>
<td>

<p>If <code>TRUE</code>, displays processing information.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Large values are recommended for <code>t.initial</code> for better performance as possible under the available computational resources.
</p>


<h3>Value</h3>

<p>A trained object consisting of the selected trees.
</p>


<h3>Note</h3>

<p>Prior action needs to be taken in the case of missing values as the fuction can not handle them at the current version.
</p>


<h3>Author(s)</h3>

<p>Zardad Khan &lt;zkhan@essex.ac.uk&gt;
</p>


<h3>References</h3>

<p>Khan, Z., Gul, A., Perperoglou, A., Miftahuddin, M., Mahmoud, O., Adler, W., &amp; Lausen, B. (2019). Ensemble of optimal trees, random forest and random projection ensemble classification. Advances in Data Analysis and Classification, 1-20.
</p>
<p>Liaw, A. and Wiener, M. (2002) “Classification and regression by random forest” R news. 2(3). 18–22.
</p>


<h3>See Also</h3>

<p><code>Predict.OTClass</code>, <code>OTReg</code>, <code>OTProb</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">#load the data

  data(Body)
  data &lt;- Body

#Divide the data into training and test parts

  set.seed(9123)
  n &lt;- nrow(data)
  training &lt;- sample(1:n,round(2*n/3))
  testing &lt;- (1:n)[-training]
  X &lt;- data[,1:24]
  Y &lt;- data[,25]

#Train OTClass on the training data

  Opt.Trees &lt;- OTClass(XTraining=X[training,],YTraining = Y[training],
  t.initial=200,method="oob+independent")

#Predict on test data

  Prediction &lt;- Predict.OTClass(Opt.Trees, X[testing,],YTesting=Y[testing])

#Objects returned

  names(Prediction)
  Prediction$Confusion.Matrix
  Prediction$Predicted.Class.Labels

</code></pre>


</div>