<div class="container">

<table style="width: 100%;"><tr>
<td>ordSelect</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Selection and smoothing of dummy coefficients of ordinal predictors</h2>

<h3>Description</h3>

<p>Fits dummy coefficients of ordinally scaled independent variables
with a group lasso penalty on differences of adjacent dummy coefficients.</p>


<h3>Usage</h3>

<pre><code class="language-R">ordSelect(x, y, u = NULL, z = NULL, offset = rep(0,length(y)), lambda,  
  model = c("linear", "logit", "poisson", "cumulative"), 
  restriction = c("refcat", "effect"), penscale = sqrt, scalex = TRUE, 
  nonpenx = NULL, control = NULL, eps = 1e-3, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>the matrix of ordinal predictors, with each column corresponding to
one predictor and containing numeric values from {1,2,...}; for each 
covariate, category 1 is taken as reference category with zero dummy 
coefficient.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>the response vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>u</code></td>
<td>
<p>a matrix (or <code>data.frame</code>) of additional categorical (nominal) 
predictors, with each column corresponding to one (additional) predictor and
containing numeric values from {1,2,...}; corresponding dummy coefficients
will not be penalized, and for each covariate category 1 is taken as reference category. Currently not supported if <code>model="cumulative"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>z</code></td>
<td>
<p>a matrix (or <code>data.frame</code>) of additional metric predictors, with 
each column corresponding to one (additional) predictor; corresponding
coefficients will not be penalized. Currently not supported if <code>model="cumulative"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>offset</code></td>
<td>
<p>vector of offset values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>vector of penalty parameters (in decreasing order).
Optimization starts with the first component. See details below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>the model which is to be fitted. Possible choices are "linear"
(default), "logit", "poisson" or "cumulative". See details below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>restriction</code></td>
<td>
<p>identifiability restriction for dummy coding. "reference" takes category 1 is as reference category (default), while with "effect" dummy coefficients sum up to 0 (known as effect coding).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penscale</code></td>
<td>
<p>rescaling function to adjust the value of the penalty
parameter to the degrees of freedom of the parameter group. See the
references below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scalex</code></td>
<td>
<p>logical. Should (split-coded) design matrix corresponding to
<code>x</code> be scaled to have unit variance over columns before fitting? See details below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nonpenx</code></td>
<td>
<p>vectors of indices indicating columns of
<code>x</code> whose regression coefficients are not penalized.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>a list of control parameters only if <code>model=="cumulative"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>a (small) constant to be added to the columnwise standard
deviations when scaling the design matrix, to control the effect of very small
stds. See details below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The method assumes that categorical covariates (contained in <code>x</code> and 
<code>u</code>) take values 1,2,...,max, where max denotes the (columnwise) highest 
level observed in the data. If any level between 1 and max is not observed for an ordinal predictor, 
a corresponding (dummy) coefficient is fitted anyway. If any level &gt; max is 
not observed but possible in principle, and a corresponding coefficient is to 
be fitted, the easiest way is to add a corresponding row to <code>x</code> (and 
<code>u</code>,<code>z</code>) with corresponding <code>y</code> value being <code>NA</code>.
</p>
<p>If a linear regression model is fitted, response vector <code>y</code> may contain 
any numeric values; if a logit model is fitted, <code>y</code> has to be 0/1 coded;
if a poisson model is fitted, <code>y</code> has to contain count data. If a cumulative   logit model is fitted, <code>y</code> takes values 1,2,...,max. 
</p>
<p>If <code>scalex</code> is <code>TRUE</code>, (split-coded) design matrix constructed from <code>x</code> is scaled to have 
unit variance over columns. If a certain <code>x</code>-category, 
however, is observed only a few times, variances may become very small and
scaling has enormous effects on the result and may cause numerical problems.
Hence a small constant <code>eps</code> can be added to each standard deviation 
when used for scaling.
</p>


<h3>Value</h3>

<p>An <code>ordPen</code> object, which is a list containing:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>fitted</code></td>
<td>
<p>the matrix of fitted response values of the training data.
Columns correspond to different <code>lambda</code> values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coefficients</code></td>
<td>
<p>the matrix of fitted coefficients with respect to 
dummy-coded (ordinal or nominal) categorical input variables (including the 
reference category) as well as metric predictors. Columns correspond to 
different lambda values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>the type of the fitted model: "linear", "logit", "poisson", or "cumulative".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>restriction</code></td>
<td>
<p>the type of restriction used for identifiability.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>the used lambda values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fraction</code></td>
<td>
<p>the used fraction values (<code>NULL</code> in case of <code>ordSelect</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xlevels</code></td>
<td>
<p>a vector giving the number of levels of the ordinal predictors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ulevels</code></td>
<td>
<p>a vector giving the number of levels of the nominal predictors (if any).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>zcovars</code></td>
<td>
<p>the number of metric covariates (if any).</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Jan Gertheiss, Aisouda Hoshiyar</p>


<h3>References</h3>

<p>Gertheiss, J., S. Hogger, C. Oberhauser and G. Tutz (2011). <em>Selection
of ordinally scaled independent variables with applications to international
classification of functioning core sets</em>.
Journal of the Royal Statistical Society C (Applied Statistics), 60, 377-395.
</p>
<p>Hoshiyar, A., Gertheiss, L.H., and Gertheiss, J. (2023). <em>Regularization and    Model Selection for Item-on-Items Regression with Applications to Food Products' Survey Data.</em> Preprint, available from https://arxiv.org/abs/2309.16373.
</p>
<p>Meier, L., S. van de Geer and P. Buehlmann (2008). <em>The
group lasso for logistic regression</em>. Journal of the Royal
Statistical Society B, 70, 53-71.
</p>
<p>Tutz, G. and J. Gertheiss (2014). <em>Rating scales as predictors â€“ the old
question of scale level and some answers</em>. Psychometrika, 79, 357-376.
</p>
<p>Tutz, G. and J. Gertheiss (2016). <em>Regularized regression for categorical
data</em>. Statistical Modelling, 16, 161-200.
</p>
<p>Yuan, M. and Y. Lin (2006). <em>Model selection and estimation in regression
with grouped variables</em>. Journal of the Royal Statistical Society B, 68, 49-67.
</p>


<h3>See Also</h3>

<p><code>plot.ordPen</code>, <code>predict.ordPen</code>, 
<code>ICFCoreSetCWP</code></p>


<h3>Examples</h3>

<pre><code class="language-R"># smoothing and selection of ordinal covariates on a simulated dataset
set.seed(123)

# generate (ordinal) predictors
x1 &lt;- sample(1:8,100,replace=TRUE)
x2 &lt;- sample(1:6,100,replace=TRUE)
x3 &lt;- sample(1:7,100,replace=TRUE)

# the response
y &lt;- -1 + log(x1) + sin(3*(x2-1)/pi) + rnorm(100)

# x matrix
x &lt;- cbind(x1,x2,x3)

# lambda values
lambda &lt;- c(1000,500,200,100,50,30,20,10,1)

# smoothing and selection
osl &lt;- ordSelect(x = x, y = y, lambda = lambda)

# results
round(osl$coef,digits=3)
plot(osl)

# If for a certain plot the x-axis should be annotated in a different way,
# this can (for example) be done as follows:
plot(osl, whx = 1, xlim = c(0,9), xaxt = "n")
axis(side = 1, at = c(1,8), labels = c("no agreement","total agreement"))
</code></pre>


</div>