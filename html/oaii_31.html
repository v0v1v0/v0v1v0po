<div class="container">

<table style="width: 100%;"><tr>
<td>feedback</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Feedback - ask chat and receive reply</h2>

<h3>Description</h3>

<p>Simple chat_request wrapper - send text to chat and get response.
</p>


<h3>Usage</h3>

<pre><code class="language-R">feedback(question, model = "gpt-3.5-turbo", max_tokens = NULL, print = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>question</code></td>
<td>
<p>string, question text</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>string, ID of the model to use. See the model endpoint compatibility table
https://platform.openai.com/docs/models/model-endpoint-compatibility
for details on which models work with the Chat API.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_tokens</code></td>
<td>
<p>NULL/int, the maximum number of tokens to generate in the chat completion</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>print</code></td>
<td>
<p>flag, If TRUE, print the answer on the console</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>string, chat answer
</p>


</div>