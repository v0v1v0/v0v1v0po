<div class="container">

<table style="width: 100%;"><tr>
<td>incRpca.block</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Incremental PCA with Block Update
</h2>

<h3>Description</h3>

<p>Sequential Karhunen-Loeve (SKL) algorithm of Levy and Lindenbaum (2000). The PCA can be updated with respect to a data matrix (not just a data vector). 
</p>


<h3>Usage</h3>

<pre><code class="language-R">incRpca.block(x, B, lambda, U, n0 = 0, f, q = length(lambda), center, byrow = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>data matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>block size</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>initial eigenvalues (optional)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>U</code></td>
<td>
<p>initial eigenvectors/PCs (optional)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n0</code></td>
<td>
<p>initial sample size (optional)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f</code></td>
<td>
<p>vector of forgetting factors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p>number of requested PCs</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>centering vector for <code>x</code> (optional)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>byrow</code></td>
<td>
<p>Are the data vectors in <code>x</code> stored in rows (TRUE) or columns (FALSE)?</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This incremental PCA algorithm utilizes QR factorization and RSVD. 
It generalizes the algorithm <code>incRpca</code> from vector to matrix/block updates. However, <code>incRpca</code> should be preferred for vector updates as it is faster.<br>
If <code>lambda</code> and <code>U</code> are specified, they are taken as the initial PCA. Otherwise, the PCA is initialized by the SVD of the first block of data in <code>x</code> (<code>B</code> data vectors). The number <code>n0</code> is the sample size before observing <code>x</code> (default value = 0). The number <code>B</code> is the size of blocks to be used in the PCA updates. Ideally, <code>B</code> should be a divisor of the number of data vectors in <code>x</code> (otherwise the last smaller block is discarded). If <code>U</code> is provided, then <code>B</code> and <code>q</code> default to the number of columns (=PC) of <code>U</code>.<br> 
The argument <code>f</code> determines the relative weight of current PCA and new data in each block update. Its length should be equal to the number of blocks in <code>x</code>, say <code class="reqn">nblock</code>. If <code>n0</code> and <code>B</code> are provided, then <code>f</code> defaults to <code>B/(n0+(0:(nblock-1)*B))</code>, i.e., the case where all data points have equal weights. The values in <code>f</code> should be in (0,1), with higher values giving more weight to new data and less to the current PCA.  
</p>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr style="vertical-align: top;">
<td><code>values</code></td>
<td>
<p>first <code>q</code> eigenvalues.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vectors</code></td>
<td>
<p>first <code>q</code> eigenvectors/PCs.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Levy, A. and Lindenbaum, M. (2000). Sequential Karhunen-Loeve basis extraction and its application to images. <em>IEEE Transactions on Image Processing</em>.
</p>


<h3>See Also</h3>

<p><code>incRpca,incRpca.rc</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Simulate Brownian Motion
n &lt;- 100 # number of sample paths
d &lt;- 50 # number of observation points
x &lt;- matrix(rnorm(n*d,sd=1/sqrt(d)),n,d)
x &lt;- t(apply(x,1,cumsum)) # dim(x) = c(100,50)
q &lt;- 10 # number of PC to compute
B &lt;- 20 # block size
n0 &lt;- B # initial sample size (if relevant)

## PCA without initial values
res1 &lt;- incRpca.block(t(x), B, q=q) # data vectors in columns
res2 &lt;- incRpca.block(x, B, q=q, byrow=TRUE) # data vectors in rows
all.equal(res1,res2) # TRUE

## PCA with initial values 
svd0 &lt;- svd(x[1:n0,], 0, n0) # use first block for initialization 
lambda &lt;- svd0$d[1:n0]^2/n0 # initial eigenvalues
U &lt;- svd0$v # initial PC
res3 &lt;- incRpca.block(x[-(1:n0),], B, lambda, U, n0, q=q, byrow=TRUE) 
# run PCA with this initialization on rest of the data 
all.equal(res1,res3) # compare with previous PCA: TRUE

## Compare with function incRpca
res4 &lt;- list(values=lambda, vectors=U)
for (i in (n0+1):n)
	res4 &lt;- incRpca(res4$values, res4$vectors, x[i,], i-1, q=q)
B &lt;- 1 # vector update
res5 &lt;- incRpca.block(x[-(1:n0),], B, lambda, U, n0, q=q, byrow=TRUE)
ind &lt;- which(sign(res5$vectors[1,]) != sign(res4$vectors[1,]))
res5$vectors[,ind] &lt;- - res5$vectors[,ind] # align PCs (flip orientation as needed)
all.equal(res4,res5) # TRUE
</code></pre>


</div>