<div class="container">

<table style="width: 100%;"><tr>
<td>ordPens-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Selection and/or Smoothing and Principal Components Analysis for Ordinal Variables
</h2>

<h3>Description</h3>

<p>Selection, and/or smoothing/fusing of ordinally scaled independent variables using 
a group lasso or generalized ridge penalty. Nonlinear principal components analysis for ordinal variables using a second-order difference penalty. 
</p>


<h3>Details</h3>


<table>
<tr>
<td style="text-align: left;">
Package: </td>
<td style="text-align: left;"> ordPens</td>
</tr>
<tr>
<td style="text-align: left;">
Type: </td>
<td style="text-align: left;"> Package</td>
</tr>
<tr>
<td style="text-align: left;">
Version: </td>
<td style="text-align: left;"> 1.1.0</td>
</tr>
<tr>
<td style="text-align: left;">
Date: </td>
<td style="text-align: left;"> 2023-07-10</td>
</tr>
<tr>
<td style="text-align: left;">
Depends: </td>
<td style="text-align: left;"> grplasso, mgcv, RLRsim, quadprog, glmpath</td>
</tr>
<tr>
<td style="text-align: left;">
Imports: </td>
<td style="text-align: left;"> ordinalNet</td>
</tr>
<tr>
<td style="text-align: left;">
Suggests: </td>
<td style="text-align: left;"> psy</td>
</tr>
<tr>
<td style="text-align: left;">
License: </td>
<td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
<td style="text-align: left;">
LazyLoad: </td>
<td style="text-align: left;"> yes</td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<p>Smoothing and selection of ordinal predictors is done by the function 
<code>ordSelect</code>; smoothing only, by <code>ordSmooth</code>; fusion and selection of ordinal predictors by <code>ordFusion</code>. For
ANOVA with ordinal factors, use <code>ordAOV</code>. Nonlinear PCA, performance evaluation and selection of an optimal 
penalty parameter can be done using <code>ordPCA</code>.
</p>


<h3>Author(s)</h3>

<p><em>Authors:</em>
Jan Gertheiss <a href="mailto:jan.gertheiss@hsu-hh.de">jan.gertheiss@hsu-hh.de</a>,
Aisouda Hoshiyar <a href="mailto:aisouda.hoshiyar@hsu-hh.de">aisouda.hoshiyar@hsu-hh.de</a>.
</p>
<p><em>Contributors:</em>
Fabian Scheipl
</p>
<p><em>Maintainer:</em> Aisouda Hoshiyar <a href="mailto:aisouda.hoshiyar@hsu-hh.de">aisouda.hoshiyar@hsu-hh.de</a>
</p>


<h3>References</h3>

<p>Gertheiss, J. (2014). <em>ANOVA for factors with ordered levels</em>, Journal of
Agricultural, Biological and Environmental Statistics, 19, 258-277.
</p>
<p>Gertheiss, J., S. Hogger, C. Oberhauser and G. Tutz (2011). <em>Selection
of ordinally scaled independent variables with applications to international
classification of functioning core sets</em>.
Journal of the Royal Statistical Society C (Applied Statistics), 60, 377-395.
</p>
<p>Gertheiss, J. and F. Oehrlein (2011). <em>Testing relevance and linearity of
ordinal predictors</em>, Electronic Journal of Statistics, 5, 1935-1959.
</p>
<p>Gertheiss, J., F. Scheipl, T. Lauer, and H. Ehrhardt (2022). <em>Statistical 
inference for ordinal predictors in generalized linear and additive models with
application to bronchopulmonary dysplasia</em>. BMC research notes, 15, 112.
</p>
<p>Gertheiss, J. and G. Tutz (2009). <em>Penalized regression with ordinal 
predictors</em>. International Statistical Review, 77, 345-365.
</p>
<p>Gertheiss, J. and G. Tutz (2010). <em>Sparse modeling of categorial explanatory
variables</em>. The Annals of Applied Statistics, 4, 2150-2180.
</p>
<p>Hoshiyar, A., H.A.L. Kiers, and J. Gertheiss (2021). <em>Penalized non-linear principal components analysis for ordinal variables with an application to international classification of functioning core sets</em>,  British Journal of Mathematical and Statistical Psychology, 76, 353-371.
</p>
<p>Hoshiyar, A., Gertheiss, L.H., and Gertheiss, J. (2023). <em>Regularization and    Model Selection for Item-on-Items Regression with Applications to Food Products' Survey Data.</em> Preprint, available from https://arxiv.org/abs/2309.16373.
</p>
<p>Tutz, G. and J. Gertheiss (2014). <em>Rating scales as predictors â€“ the old
question of scale level and some answers</em>. Psychometrica, 79, 357-376.
</p>
<p>Tutz, G. and J. Gertheiss (2016). <em>Regularized regression for categorical
data</em>. Statistical Modelling, 16, 161-200.
</p>


<h3>See Also</h3>

<p><code>ordSelect</code>, <code>ordSmooth</code>, 
<code>ordFusion</code>, <code>ordAOV</code>, <code>ordPCA</code> </p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
### smooth modeling of a simulated dataset
set.seed(123)

# generate (ordinal) predictors
x1 &lt;- sample(1:8,100,replace=TRUE)
x2 &lt;- sample(1:6,100,replace=TRUE)
x3 &lt;- sample(1:7,100,replace=TRUE)

# the response
y &lt;- -1 + log(x1) + sin(3*(x2-1)/pi) + rnorm(100)

# x matrix
x &lt;- cbind(x1,x2,x3)

# lambda values
lambda &lt;- c(1000,500,200,100,50,30,20,10,1)

# smooth modeling
o1 &lt;- ordSmooth(x = x, y = y, lambda = lambda)

# results
round(o1$coef,digits=3)
plot(o1)

# If for a certain plot the x-axis should be annotated in a different way,
# this can (for example) be done as follows:
plot(o1, whx = 1, xlim = c(0,9), xaxt = "n")
axis(side = 1, at = c(1,8), labels = c("no agreement","total agreement"))


### nonlinear PCA on chronic widespread pain data 
# load example data 
data(ICFCoreSetCWP)

# adequate coding to get levels 1,..., max 
H &lt;- ICFCoreSetCWP[, 1:67] + matrix(c(rep(1, 50), rep(5, 16), 1),
                                    nrow(ICFCoreSetCWP), 67, 
                                    byrow = TRUE)

# nonlinear PCA
ordPCA(H, p = 2, lambda = 0.5, maxit = 1000,
       Ks = c(rep(5, 50), rep(9, 16), 5), 
       constr = c(rep(TRUE, 50), rep(FALSE, 16), TRUE))


# k-fold cross-validation
set.seed(1234)
lambda &lt;- 10^seq(4,-4, by = -0.1) 
cvResult1 &lt;- ordPCA(H, p = 2, lambda = lambda, maxit = 100,
       Ks = c(rep(5, 50), rep(9, 16), 5), 
       constr = c(rep(TRUE, 50), rep(FALSE, 16), TRUE),
       CV = TRUE, k = 5)
            
# optimal lambda                    
lambda[which.max(apply(cvResult1$VAFtest,2,mean))]                      

## End(Not run)
</code></pre>


</div>