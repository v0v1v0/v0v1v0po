<div class="container">

<table style="width: 100%;"><tr>
<td>harsm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Friendly interface to softmax regression under Harville model.</h2>

<h3>Description</h3>

<p>A user friendly interface to the softmax regression under the Harville
model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">harsm(formula, data, group = NULL, weights = NULL,
  na.action = na.omit)

## S3 method for class 'harsm'
vcov(object, ...)

## S3 method for class 'harsm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>an object of class <code>"formula"</code> (or one that
can be coerced to that class): a symbolic description of the
model to be fitted.  The details of model specification are given
under ‘Details’.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>an optional data frame, list or environment (or object
coercible by <code>as.data.frame</code> to a data frame) containing
the variables in the model.  If not found in <code>data</code>, the
variables are taken from <code>environment(formula)</code>,
typically the environment from which <code>lm</code> is called.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group</code></td>
<td>
<p>the string name of the group variable in the data,
or a bare character with the group name. The group indices
need not be integers, but that is more efficient. 
They need not be sorted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>an optional vector of weights, or the string or bare name of the 
weights in the <code>data</code> for use in the fitting process. The weights
are attached to the outcomes, not the participant.  Set to <code>NULL</code>
for none.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>
<p>How to deal with missing values in the outcomes,
groups, weights, etc.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>an object of class <code>harsm</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments to be passed to the low level
regression fitting functions (see below).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>logicals.  If <code>TRUE</code> the corresponding
components of the fit (the model frame, the model matrix, the
response, the QR decomposition) are returned.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Performs a softmax regression by groups, via Maximum Likelihood Estimation,
under the Harville model. 
We fit <code class="reqn">\beta</code> where odds are <code class="reqn">\eta = x^{\top}\beta</code> for 
independent variables <code class="reqn">x</code>. 
The probability of taking first place is then <code class="reqn">\mu=c\exp{\eta}</code>,
where the <code class="reqn">c</code> is chosen so the <code class="reqn">\mu</code> sum to one.
Under the Harville model, conditional on the first place finisher
having been observed, the probability model for second
(and successive) places with the probabilities of the remaining
participants renormalized.
</p>
<p>The <code>print</code> method of the <code>harsm</code> object includes
a display of the R-squared. This measures the improvement
in squared errors of the expected rank from the model
over the null model which posits that all odds are equal.
When the formula includes an offset, a ‘delta R-squared’
is also output. This is the improvement in predicted
ranks over the model based on the offset term.
Note that the expected ranks are only easy to produce
under the Harville model; under the Henery model, 
the summary R-squared statistics are not produced.
Note that this computation uses weighted sums of squares,
as the weights contribute to the likelihood term.
However, the square sum computation does not take into
account the standard error of the rank, and so
unlike in linear regression, the softmax regression
does not always give positive R-squareds,
and the statistic is otherwise hard to interpret.
</p>


<h3>Value</h3>

<p>An object of class <code>harsm</code>, but also of <code>maxLik</code> with the
fit.
</p>


<h3>Note</h3>

<p>Since version 0.1.0 of this package, the
normalization of weights used in this function
have changed under the hood. This is to
give correct inference in the case where
zero weights are used to signify finishing
places were not observed. If in doubt,
please confirm inference by simulations,
taking as example the simulations in the README.
</p>
<p>This regression may give odd results when the outcomes are tied,
imposing an arbitrary order on the tied outcomes.
Moreover, no warning may be issued in this case.
In future releases, ties may be dealt with differently,
perhaps in analogy to how ties are treated in the
Cox Proportional Hazards regression, using
the methods of Breslow or Efron.
</p>
<p>To avoid incorrect inference when only the top
performers are recorded, and all others are 
effectively tied, one should use weighting.
Set the weights to zero for participants who
are tied non-winners, and one for the rest
So for example, if you observe the Gold, Silver,
and Bronze medal winners of an Olympic event
that had a starting field of 12 participants,
set weights to 1 for the medal winners, and 0
for the others. Note that the weights do not
attach to the participants, they attach to
the place they took.
</p>


<h3>Author(s)</h3>

<p>Steven E. Pav <a href="mailto:shabbychef@gmail.com">shabbychef@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code>harsmfit</code>, <code>harsmlik</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
nfeat &lt;- 5
set.seed(1234)
g &lt;- ceiling(seq(0.1,1000,by=0.1))
X &lt;- matrix(rnorm(length(g) * nfeat),ncol=nfeat)
beta &lt;- rnorm(nfeat)
eta &lt;- X %*% beta
y &lt;- rsm(eta,g)
# now the pretty frontend
data &lt;- cbind(data.frame(outcome=y,race=g),as.data.frame(X))

fmla &lt;- outcome ~ V1 + V2 + V3 + V4 + V5
fitm &lt;- harsm(fmla,data,group=race)

eta0 &lt;- rowMeans(X)
data &lt;- cbind(data.frame(outcome=y,race=g,eta0=eta0),as.data.frame(X))
fmla &lt;- outcome ~ offset(eta0) + V1 + V2 + V3 + V4 + V5
fitm &lt;- harsm(fmla,data,group=race)

# with weights
data &lt;- cbind(data.frame(outcome=y,race=g,eta0=eta0),as.data.frame(X))
data$wts &lt;- runif(nrow(data),min=1,max=2)
fmla &lt;- outcome ~ offset(eta0) + V1 + V2 + V3 + V4 + V5
fitm &lt;- harsm(fmla,data,group=race,weights=wts)

# softmax on the Best Picture data
data(best_picture)
df &lt;- best_picture
df$place &lt;- ifelse(df$winner,1,2)
df$weight &lt;- ifelse(df$winner,1,0)

fmla &lt;- place ~ nominated_for_BestDirector + nominated_for_BestActor + Drama 

harsm(fmla,data=df,group=year,weights=weight) 


# test against logistic regression
if (require(dplyr)) {
nevent &lt;- 10000
set.seed(1234)
adf &lt;- data_frame(eventnum=floor(seq(1,nevent + 0.7,by=0.5))) %&gt;%
  mutate(x=rnorm(n()),
         program_num=rep(c(1,2),nevent),
         intercept=as.numeric(program_num==1),
         eta=1.5 * x + 0.3 * intercept,
         place=ohenery::rsm(eta,g=eventnum))

# Harville model
modh &lt;- harsm(place ~ intercept + x,data=adf,group=eventnum)

# the collapsed data.frame for glm
ddf &lt;- adf %&gt;%
  arrange(eventnum,program_num) %&gt;%
  group_by(eventnum) %&gt;%
    summarize(resu=as.numeric(first(place)==1),
              delx=first(x) - last(x),
              deli=first(intercept) - last(intercept)) %&gt;%
  ungroup()

# glm logistic fit
modg &lt;- glm(resu ~ delx + 1,data=ddf,family=binomial(link='logit'))

all.equal(as.numeric(coef(modh)),as.numeric(coef(modg)),tolerance=1e-4)
all.equal(as.numeric(vcov(modh)),as.numeric(vcov(modg)),tolerance=1e-4)
}



</code></pre>


</div>