<div class="container">

<table style="width: 100%;"><tr>
<td>find_optimal</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Find an optimal classification among competing clustering solutions</h2>

<h3>Description</h3>

<p><code>find_optimal</code> takes a clustering solution, or a set of related clustering solutions, fits models based on the underlying multivariate data, and calculates the sum-of-AIC value for the solution/s. The smallest sum-of-AIC value is the optimal solution.
</p>


<h3>Usage</h3>

<pre><code class="language-R">find_optimal(data, clustering, family, K = 1, cutree = NULL,
  cutreeLevels = 2:10, cutreeOveride = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a data frame (or object that can be coerced by <code>as.data.frame</code> containing the "raw" multivariate data. This is not necessarily the data used by the clustering algorithm - it is the data on which you are testing the predictive ability of the clustering solutions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>clustering</code></td>
<td>
<p>either an object on which <code>cutree</code> will work, or a list with one or more components, each containing an atomic vector of cluster labels (that can be coerced by <code>as.factor</code>). The number of cluster labels (either generated by <code>cutree</code> or supplied in each list component) must match the number of rows of the object supplied in the <code>data</code> argument.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>a character string denoting the error distribution to be used for model fitting. The options are similar to those in <code>family</code>, but are more limited - see Details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>number of trials in binomial regression. By default, K=1 for presence-absence data (with cloglog link).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cutree</code></td>
<td>
<p>logical, but default is <code>NULL</code> for auto-detection. Whether <code>cutree</code> should be used on the object supplied to the <code>clustering</code> argument</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cutreeLevels</code></td>
<td>
<p>a numerical vector specifying the different partitioning levels to calculate sum-of-AIC for (that is the values of <code>k</code> to be supplied to <code>cutree</code>). Ignored if <code>cutree = FALSE</code>, as the number of partitions will be automatically generated from the number of unique levels in each component of <code>clustering</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cutreeOveride</code></td>
<td>
<p>logical. Ignored if <code>cutree = FALSE</code>. Should the checks on whether the object supplied to the <code>clustering</code> works with <code>cutree</code>? WARNING: only set <code>cutreeOveride = TRUE</code> if you are totally sure <code>cutree</code> works, but the error message is telling you it doesn't. See Arguments in <code>cutree</code> and first consider modifying the object supplied to clustering=.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>find_optimal</code> is built on the premise that a <em>good</em> clustering solution (i.e. a classification) should provide information about the composition and abundance of the multivariate data it is classifying. A natural way to formalize this is with a predictive model, where group membership (clusters) is the predictor, and the multivariate data (site by variables matrix) is the response. <code>find_optimal</code> fits linear models to each variable, and calculates the sum of the AIC value (sum-of-AIC) for each model. sum-of-AIC is motivated as an estimate of Kullback-Leibler distance, so we posit that the clustering solution that minimises the sum-of-AIC value is the <em>best</em>. So, in context of optimal partitioning, <code>find_optimal</code> can be used to automatically and objectively decide which clustering solution is the best among competing solutions. Lyons et al. (2016) provides background, a detailed description of the methodology, and application of sum-of-AIC on both real and simulated ecological multivariate abundance data.
</p>
<p>At present, <code>find_optimal</code> supports the following error distributions for model fitting:
</p>

<ul>
<li>
<p> Gaussian (LM)
</p>
</li>
<li>
<p> Negative Binomial (GLM with log link)
</p>
</li>
<li>
<p> Poisson (GLM with log link)
</p>
</li>
<li>
<p> Binomial (GLM with cloglog link for binary data, logit link otherwise)
</p>
</li>
<li>
<p> Ordinal (Proportional odds model with logit link)
</p>
</li>
</ul>
<p>Gaussian LMs should be used for 'normal' data. Negative Binomial and Poisson GLMs should be used for count data. Binomial GLMs should be used for binary and presence/absence data (when <code>K=1</code>), or trials data (e.g. frequency scores). If Binomial regression is being used with <code>K&gt;1</code>, then <code>data</code> should be numerical values between 0 and 1, interpreted as the proportion of successful cases, where the total number of cases is given by <code>K</code> (see Details in <code>family</code>). Ordinal regression should be used for ordinal data, for example, cover-abundance scores. For ordinal regression, data should be supplied as either 1) factors, with the appropriate ordinal level order specified (see <code>levels</code>) or 2) numeric, which will be coerced into a factor with levels ordered in numerical order (e.g. cover-abundance/numeric response scores). LMs fit via <code>manylm</code>; GLMs fit via <code>manyglm</code>; proportional odds model fit via <code>clm</code>.
</p>


<h3>Value</h3>

<p>a data frame containing the sum-of-AIC value for each clustering solution, along with the number of clusters the solution had. The object is of class <code>aicsums</code>.
</p>
<p>Attributes for the data frame are:
</p>

<dl>
<dt><code>family</code></dt>
<dd>
<p> which error distribution was used for modelling, see Arguments</p>
</dd>
<dt><code>K</code></dt>
<dd>
<p> number of cases for Binomial regression, see Arguments</p>
</dd>
<dt><code>cutree</code></dt>
<dd>
<p> whether <code>cutree</code> was used, see Arguments</p>
</dd>
<dt><code>cutreeLevels</code></dt>
<dd>
<p> number of partitioning levels specified, see Arguments</p>
</dd>
</dl>
<h3>Author(s)</h3>

<p>Mitchell Lyons
</p>


<h3>References</h3>

<p>Lyons et al. 2016. Model-based assessment of ecological community classifications. <em>Journal of Vegetation Science</em>, <strong>27 (4)</strong>: 704â€“715.
</p>


<h3>See Also</h3>

<p><code>plot.aicsums</code>, <code>get_characteristic</code>, <code>merge_clusters</code>, S3 for residual plots (at some stage)
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Prep the 'swamps' data
## ======================

data(swamps) # see ?swamps
swamps &lt;- swamps[,-1]

## Assess clustering solutions using cutree() method
## =================================================

## perhaps not the best clustering option, but this is base R
swamps_hclust &lt;- hclust(d = dist(x = log1p(swamps), method = "canberra"),
                       method = "complete")

## calculate sum-of-AIC values for 10:25 clusters, using the hclust() output
swamps_hclust_aics &lt;- find_optimal(data = swamps, clustering = swamps_hclust,
family = "poisson", cutreeLevels = 10:25)

## Looks like ~20 clusters is where predictive performance levels off

## Note here that the data passed to find_optimal() was actually NOT the
## data used for clustering (transform/distance), rather it was the
## original abundance (response) data of interest

## plot - lower sum-of-AIC valuea indicate 'better' clustering
plot(swamps_hclust_aics)


## Not run: 
## Assess clustering solutions by supplying a list of solutions
## ============================================================

## again, we probably wouldn't do this, but for illustrative purposes
## note that we are generating a list of solutions this time
swamps_kmeans &lt;- lapply(X = 2:40,
FUN = function(x, data) {stats::kmeans(x = data, centers = x)$cluster},
data = swamps)

## calculate sum-of-AIC values for the list of clustering solutions
swamps_kmeans_aics &lt;- find_optimal(data = swamps, clustering = swamps_kmeans,
family = "poisson") # note cutreeLevels= argument is not needed

plot(swamps_kmeans_aics)

## End(Not run)

## See vignette for more explanation than this example
## ============================================================

</code></pre>


</div>