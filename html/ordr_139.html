<div class="container">

<table style="width: 100%;"><tr>
<td>lda-ord</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Augmented implementation of linear discriminant analysis</h2>

<h3>Description</h3>

<p>This function replicates <code>MASS::lda()</code> with options to retain
elements useful to the tbl_ord class and biplot calculations.
</p>


<h3>Usage</h3>

<pre><code class="language-R">lda_ord(x, ...)

## S3 method for class 'formula'
lda_ord(formula, data, ..., subset, na.action)

## S3 method for class 'data.frame'
lda_ord(x, ...)

## S3 method for class 'matrix'
lda_ord(x, grouping, ..., subset, na.action)

## Default S3 method:
lda_ord(
  x,
  grouping,
  prior = proportions,
  tol = 1e-04,
  method = c("moment", "mle", "mve", "t"),
  CV = FALSE,
  nu = 5,
  ...,
  ret.x = FALSE,
  ret.grouping = FALSE,
  axes.scale = "unstandardized"
)

## S3 method for class 'lda_ord'
predict(
  object,
  newdata,
  prior = object$prior,
  dimen,
  method = c("plug-in", "predictive", "debiased"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>(required if no formula is given as the principal argument.)
a matrix or data frame or Matrix containing the explanatory variables.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>arguments passed to or from other methods.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>

<p>A formula of the form <code>groups ~ x1 + x2 + ...</code>  That is, the
response is the grouping factor and the right hand side specifies
the (non-factor) discriminators.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>An optional data frame, list or environment from which variables
specified in <code>formula</code> are preferentially to be taken.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>

<p>An index vector specifying the cases to be used in the training
sample.  (NOTE: If given, this argument must be named.)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>

<p>A function to specify the action to be taken if <code>NA</code>s are found.
The default action is for the procedure to fail.  An alternative is
<code>na.omit</code>, which leads to rejection of cases with missing values on
any required variable.  (NOTE: If given, this argument must be named.)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>grouping</code></td>
<td>

<p>(required if no formula principal argument is given.)
a factor specifying the class for each observation.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>

<p>the prior probabilities of class membership.  If unspecified, the
class proportions for the training set are used.  If present, the
probabilities should be specified in the order of the factor
levels.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>

<p>A tolerance to decide if a matrix is singular; it will reject variables
and linear combinations of unit-variance variables whose variance is
less than <code>tol^2</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p><code>"moment"</code> for standard estimators of the mean and variance,
<code>"mle"</code> for MLEs, <code>"mve"</code> to use <code>cov.mve</code>, or
<code>"t"</code> for robust estimates based on a <code class="reqn">t</code> distribution.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CV</code></td>
<td>

<p>If true, returns results (classes and posterior probabilities) for
leave-one-out cross-validation. Note that if the prior is estimated,
the proportions in the whole dataset are used.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nu</code></td>
<td>

<p>degrees of freedom for <code>method = "t"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ret.x, ret.grouping</code></td>
<td>
<p>Logical; whether to retain as attributes the data
matrix (<code>x</code>) and the class assignments (<code>grouping</code>) on which LDA is
performed. Methods like <code>predict()</code> access these objects by name in the
parent environment, and retaining them as attributes prevents errors that
arise if these objects are reassigned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>axes.scale</code></td>
<td>
<p>Character string indicating how to left-transform the
<code>scaling</code> value when rendering biplots using <code>ggbiplot()</code>. Options include
<code>"unstandardized"</code>, <code>"standardized"</code>, and <code>"contribution"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>

<p>object  of class <code>"lda"</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newdata</code></td>
<td>

<p>data frame of cases to be classified or, if <code>object</code>
has a formula, a data frame with columns of the same names as the
variables used.  A vector will be interpreted
as a row vector.  If newdata is missing, an attempt will be
made to retrieve the data used to fit the <code>lda</code> object.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dimen</code></td>
<td>

<p>the dimension of the space to be used. If this is less than <code>min(p, ng-1)</code>,
only the first <code>dimen</code> discriminant components are used (except for
<code>method="predictive"</code>), and only those dimensions are returned in <code>x</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Linear discriminant analysis relies on an eigendecomposition of the product
<code class="reqn">W^{-1}B</code> of the inverse of the within-class covariance matrix <code class="reqn">W</code> by
the between-class covariance matrix <code class="reqn">B</code>. This eigendecomposition can be
motivated as the right (<code class="reqn">V</code>) half of the singular value decomposition of
the matrix of <em>Mahalanobis distances</em> between the cases after "sphering"
(linearly transforming them so that the within-class covariance is the
identity matrix). LDA are not traditionally represented as biplots, with some
exceptions (Gardner &amp; le Roux, 2005; Greenacre, 2010, p. 109–117).
</p>
<p>LDA is implemented as <code>MASS::lda()</code> in the <strong>MASS</strong> package, in which the
variables are transformed by a sphering matrix <code class="reqn">S</code> (Venables &amp; Ripley,
2003, p. 331–333). The returned element <code>scaling</code> contains the
unstandardized <em>discriminant coefficients</em>, which define the discriminant
scores of the cases and their centroids as linear combinations of the
original variables.
</p>
<p>The discriminant coefficients constitute one of several possible choices of
axes for a biplot representation of the LDA. The slightly modified function
<code>lda_ord()</code> provides additional options:
</p>

<ul>
<li>
<p> The <em>standardized discriminant coefficients</em> are obtained by (re)scaling
the coefficients by the variable standard deviations. These coefficients
indicate the contributions of the variables to the discriminant scores after
controlling for their variances (Orlov, 2013).
</p>
</li>
<li>
<p> The variables' <em>contributions</em> to the Mahalanobis variance along each
discriminant axis are obtained by transforming the coefficients by the
inverse of the sphering matrix <code class="reqn">S</code>. Because the contribution biplot
derives from the eigendecomposition of the Mahalanobis distance matrix, the
projections of the centroids and cases onto the variable axes approximate
their variable values after centering and sphering (Greenacre, 2013).
</p>
</li>
</ul>
<h3>Value</h3>

<p>Output from <code>MASS::lda()</code> with an additional preceding class
'lda_ord' and up to three attributes:
</p>

<ul>
<li>
<p> the input data <code>x</code>, if <code>ret.x = TRUE</code>
</p>
</li>
<li>
<p> the class assignments <code>grouping</code>, if <code>ret.grouping = TRUE</code>
</p>
</li>
<li>
<p> if the parameter <code>axes.scale</code> is not 'unstandardized', a matrix
<code>axes.scale</code> that encodes the transformation of the row space
</p>
</li>
</ul>
<h3>References</h3>

<p>Gardner S &amp; le Roux NJ (2005) "Extensions of Biplot Methodology to
Discriminant Analysis". <em>Journal of Classification</em> <strong>22</strong>(1): 59–86.
<a href="https://doi.org/10.1007/s00357-005-0006-7">doi:10.1007/s00357-005-0006-7</a>
<a href="https://link.springer.com/article/10.1007/s00357-005-0006-7">https://link.springer.com/article/10.1007/s00357-005-0006-7</a>
</p>
<p>Greenacre MJ (2010) <em>Biplots in Practice</em>. Fundacion BBVA, ISBN:
978-84-923846.
<a href="https://www.fbbva.es/microsite/multivariate-statistics/biplots.html">https://www.fbbva.es/microsite/multivariate-statistics/biplots.html</a>
</p>
<p>Venables WN &amp; Ripley BD (2003) <em>Modern Applied Statistics with S</em>, Fourth
Edition. Springer Science &amp; Business Media, ISBN: 0387954570, 9780387954578.
<a href="https://www.mimuw.edu.pl/~pokar/StatystykaMgr/Books/VenablesRipley_ModernAppliedStatisticsS02.pdf">https://www.mimuw.edu.pl/~pokar/StatystykaMgr/Books/VenablesRipley_ModernAppliedStatisticsS02.pdf</a>
</p>
<p>Orlov K (2013) <em>Answer to</em> "Algebra of LDA. Fisher discrimination power of a
variable and Linear Discriminant Analysis". CrossValidated, accessed
2019-07-26. <a href="https://stats.stackexchange.com/a/83114/68743">https://stats.stackexchange.com/a/83114/68743</a>
</p>
<p>Greenacre M (2013) "Contribution Biplots". <em>Journal of Computational and
Graphical Statistics</em>, <strong>22</strong>(1): 107–122.
<a href="https://amstat.tandfonline.com/doi/full/10.1080/10618600.2012.702494">https://amstat.tandfonline.com/doi/full/10.1080/10618600.2012.702494</a>
</p>


<h3>See Also</h3>

<p><code>MASS::lda()</code>, from which <code>lda_ord()</code> is adapted
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Anderson iris species data centroid
iris_centroid &lt;- t(apply(iris[, 1:4], 2, mean))
# unstandardized discriminant coefficients: the discriminant axes are linear
# combinations of the centered variables
iris_lda &lt;- lda_ord(iris[, 1:4], iris[, 5], axes.scale = "unstandardized")
# linear combinations of centered variables
print(sweep(iris_lda$means, 2, iris_centroid, "-") %*% get_cols(iris_lda))
# discriminant centroids
print(get_rows(iris_lda, elements = "active"))

# unstandardized coefficient LDA biplot
iris_lda %&gt;%
  as_tbl_ord() %&gt;%
  augment_ord() %&gt;%
  mutate_rows(
    species = grouping,
    discriminant = ifelse(.element == "active", "centroid", "case")
  ) %&gt;%
  ggbiplot() +
  theme_bw() +
  geom_rows_point(aes(
    color = grouping,
    size = discriminant, alpha = discriminant
  )) +
  geom_cols_vector(color = "#888888") +
  geom_cols_text_radiate(aes(label = name), size = 3) +
  scale_color_brewer(type = "qual", palette = 2) +
  ggtitle("Unstandardized coefficient biplot of iris LDA") +
  expand_limits(y = c(-3, 5))

# standardized discriminant coefficients: permit comparisons across the
# variables
iris_lda &lt;- lda_ord(iris[, 1:4], iris[, 5], axes.scale = "standardized")
# standardized variable contributions to discriminant axes
iris_lda %&gt;%
  as_tbl_ord() %&gt;%
  augment_ord() %&gt;%
  fortify(.matrix = "cols") %&gt;%
  dplyr::mutate(variable = name) %&gt;%
  tidyr::gather(discriminant, coefficient, LD1, LD2) %&gt;%
  ggplot(aes(x = discriminant, y = coefficient, fill = variable)) +
  geom_bar(position = "dodge", stat = "identity") +
  labs(y = "Standardized coefficient", x = "Linear discriminant") +
  theme_bw() +
  coord_flip()
# standardized coefficient LDA biplot
iris_lda %&gt;%
  as_tbl_ord() %&gt;%
  augment_ord() %&gt;%
  mutate_rows(
    species = grouping,
    discriminant = ifelse(.element == "active", "centroid", "case")
  ) %&gt;%
  ggbiplot() +
  theme_bw() +
  geom_rows_point(aes(
    color = grouping,
    size = discriminant, alpha = discriminant
  )) +
  geom_cols_vector(color = "#888888") +
  geom_cols_text_radiate(aes(label = name), size = 3) +
  scale_color_brewer(type = "qual", palette = 2) +
  ggtitle("Standardized coefficient biplot of iris LDA") +
  expand_limits(y = c(-2, 3))

# variable contributions (de-sphered discriminant coefficients): recover the
# inner product relationship with the centered class centroids
iris_lda &lt;- lda_ord(iris[, 1:4], iris[, 5], axes.scale = "contribution")
# symmetric square root of within-class covariance
C_W_eig &lt;- eigen(cov(iris[, 1:4] - iris_lda$means[iris[, 5], ]))
C_W_sqrtinv &lt;-
  C_W_eig$vectors %*% diag(1/sqrt(C_W_eig$values)) %*% t(C_W_eig$vectors)
# product of matrix factors (scores and loadings)
print(get_rows(iris_lda, elements = "active") %*% t(get_cols(iris_lda)))
# "asymmetric" square roots of Mahalanobis distances between variables
print(sweep(iris_lda$means, 2, iris_centroid, "-") %*% C_W_sqrtinv)
# contribution LDA biplot
iris_lda %&gt;%
  as_tbl_ord() %&gt;%
  augment_ord() %&gt;%
  mutate_rows(
    species = grouping,
    discriminant = ifelse(.element == "active", "centroid", "case")
  ) %&gt;%
  ggbiplot() +
  theme_bw() +
  geom_rows_point(aes(
    color = grouping,
    size = discriminant, alpha = discriminant
  )) +
  geom_cols_vector(color = "#888888") +
  geom_cols_text_radiate(aes(label = name), size = 3) +
  scale_color_brewer(type = "qual", palette = 2) +
  ggtitle("Contribution biplot of iris LDA") +
  expand_limits(y = c(-2, 3.5))
</code></pre>


</div>