<div class="container">

<table style="width: 100%;"><tr>
<td>kullback_leibler_cont_appr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Calculate a Continuous Approximation of the Kullback-Leibler Divergence</h2>

<h3>Description</h3>

<p>Calculate a Continuous Approximation of the Kullback-Leibler Divergence
</p>


<h3>Usage</h3>

<pre><code class="language-R">kullback_leibler_cont_appr(p, q)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>(numeric) probabilities</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p>(numeric) probabilities</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The continuous approximation of the Kullback-Leibler divergence
is calculated as follows:
</p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{n}\sum_{i=1}^n\big[\log(p_i) p_i - \log(q_i) p_i \big]
</code>
</p>



<h3>Value</h3>

<p>Numeric vector
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Simulate n normally distributed variates
n &lt;- 1000
dist1 &lt;- rnorm(n)
dist2 &lt;- rnorm(n, mean = 0, sd = 2)
dist3 &lt;- rnorm(n, mean = 2, sd = 2)

# Estimate probability density functions
pdf1 &lt;- density(dist1)
pdf2 &lt;- density(dist2)
pdf3 &lt;- density(dist3)

# Visualise PDFs
plot(pdf1, main = "PDFs", col = "red", xlim = range(dist3))
lines(pdf2, col = "blue")
lines(pdf3, col = "green")

# PDF 1 vs PDF 2
kullback_leibler_cont_appr(pdf1$y, pdf2$y)

# PDF 1 vs PDF 3
kullback_leibler_cont_appr(pdf1$y, pdf3$y)

# PDF 2 vs PDF 2
kullback_leibler_cont_appr(pdf2$y, pdf3$y)
</code></pre>


</div>